{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import pandas as pd  # for handling dataframes\n",
    "import seaborn as sns  # for visualization\n",
    "import matplotlib.pyplot as plt  # for plotting graphs\n",
    "import numpy as np  # for numerical computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn Libraries\n",
    "from sklearn.preprocessing import StandardScaler  # for feature scaling\n",
    "from sklearn.model_selection import train_test_split  # for splitting data\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow & Keras\n",
    "import tensorflow as tf  \n",
    "from tensorflow.keras.models import Sequential, load_model  # tensorflow keras API \n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Activation  # tensorflow keras layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint  # callbacks for training\n",
    "from tensorflow.keras.optimizers import Adam  # optimizer\n",
    "from tensorflow.keras.utils import pad_sequences  # utility function for sequence padding\n",
    "from tensorflow.keras import layers # import layers explicitly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789bba86",
   "metadata": {},
   "source": [
    "**Feature set description**\n",
    "\n",
    "|**Feature**         |**Description**|\n",
    "|----------------|:----------------|\n",
    "|Date Time       | year-month-day hour:minute:second   |\n",
    "|Appliances      | energy use in Wh|\n",
    "|lights          | energy use of light fixtures in the house in Wh|\n",
    "|T1              | Temperature in kitchen area, in Celsius|\n",
    "|RH_1            | Temperature in kitchen area, in Celsius|\n",
    "|T2              | Temperature in living room area, in Celsius\n",
    "|RH_2            | Humidity in living room area, in %\n",
    "|T3              | Temperature in laundry room area\n",
    "|RH_3            | Humidity in laundry room area, in %\n",
    "|T4              | Temperature in office room, in Celsius\n",
    "|RH_4            | Humidity in office room, in %\n",
    "|T5              | Temperature in bathroom, in Celsius\n",
    "|RH_5            | Humidity in bathroom, in %\n",
    "|T6              | Temperature outside the building (north side), in Celsius\n",
    "|RH_6            | Humidity outside the building (north side), in %\n",
    "|T7              | Temperature in ironing room , in Celsius\n",
    "|RH_7            | Humidity in ironing room, in %\n",
    "|T8              | Temperature in teenager room 2, in Celsius\n",
    "|RH_8            | Humidity in teenager room 2, in %\n",
    "|T9              | Temperature in parents room, in Celsius\n",
    "|RH_9            | Humidity in parents room, in %\n",
    "|To              | Temperature outside (from Chievres weather station), in Celsius\n",
    "|Pressure (from Chievres weather station) | in mm Hg\n",
    "|RH_out Humidity outside (from Chievres weather station) | in %\n",
    "|Wind speed (from Chievres weather station) | in m/s\n",
    "|Visibility (from Chievres weather station) | in km\n",
    "|Tdewpoint (from Chievres weather station) | Â°C\n",
    "|rv1 | Random variable 1 nondimensional\n",
    "|rv2 | Random variable 2 nondimensional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'energydata_complete.csv'\n",
    "\n",
    "# Read our dataset into our dataframe\n",
    "df = pd.read_csv(file_path)\n",
    "df_raw = df.copy()\n",
    "\n",
    "# Print the head of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26759b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the features\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf02485c",
   "metadata": {},
   "source": [
    "Per our output, we see not missing values in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b178094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conver date to Datetime format\n",
    "df['Datetime'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify our dataframe types \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb670b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round all values to 2 decimal places for easier processing and formatting\n",
    "df = df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate our rounding\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f75725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Date' column\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# Move the 'Datetime' column to the first position\n",
    "df = df[['Datetime'] + [col for col in df.columns if col != 'Datetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec48a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfdd85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure size\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot the heatmap\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', fmt=\".2f\", cbar=True)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Heatmap of Correlations Between Variables', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf73670",
   "metadata": {},
   "source": [
    "The below features were chosen based on their strong correlation with Appliances (energy consumption) while avoiding redundant or weak predictors. <br>\n",
    "lights was included because lighting directly contributes to household energy use. Indoor temperature features (T1, T2) were selected as they <br>\n",
    "impact HVAC operations, which are a major factor in energy consumption. T_out (outdoor temperature) and Tdewpoint were chosen because external <br>\n",
    "weather conditions influence heating and cooling requirements inside the home. RH_out (outdoor humidity) and Windspeed were kept as they can affect <br>\n",
    "temperature regulation and ventilation needs. Finally, hour was included to capture daily energy usage patterns, as appliance consumption tends to <br>\n",
    "vary throughout the day. These features provide a balanced mix of internal conditions, external environmental influences, and time-based patterns, <br>\n",
    "ensuring the model captures key factors affecting energy consumption.\n",
    "\n",
    "|**Feature**         |**Description**|\n",
    "|----------------|:----------------|\n",
    "|lights                    | Directly affects energyh consumption  |\n",
    "|T1 (Kitchen Temp)         | Strong correlation with Appliances    |\n",
    "|T2 (Living Room Temp)     | Represents HVAC energy use            |\n",
    "|T_out (Outside Temp)      | External factor on energy consumption |\n",
    "|RH_out (Outdoor Humidity) | Impcasts cooling and heating          | \n",
    "|Windspeed                 | Influences temp reulation             | \n",
    "|Tdewpoint                 | Outdoor conditions                    | \n",
    "|hour                      | Captures time-based energy patterns   | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af254f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a distribution of the energy consumption\n",
    "sns.histplot(df['Appliances'], bins=30, kde=True)\n",
    "plt.title(\"Appliances Energy Consumption Distribution\")\n",
    "plt.xlabel(\"Energy Consumption (Wh)\")\n",
    "plt.ylabel(\"Occurrence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54999a3a",
   "metadata": {},
   "source": [
    "1. We can see from our distribution plot for energy consumption that most of the consumption is < 200 Wh\n",
    "2. A sharp peak > 50 Wh < 100 Wh suggests many appliances consume low energy. \n",
    "3. We have a right skewed plot, dmeonstrating that anything > 400 Wh is rare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a683e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time-based features\n",
    "df['hour'] = df['Datetime'].dt.hour  # Extract hour of the day (0-23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d33e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot raw data (individual appliance consumption points)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(df['hour'], df['Appliances'], alpha=0.3, color='blue', label=\"Appliance Energy Consumption\")\n",
    "\n",
    "# Overlay the 24-hour average trend\n",
    "hourly_avg = df.groupby('hour')['Appliances'].mean()\n",
    "plt.plot(hourly_avg.index, hourly_avg.values, marker='o', linestyle='-', color='red', label=\"Hourly Average\")\n",
    "\n",
    "# Plot our hourly average across the dataset\n",
    "plt.xlabel(\"Hour of the Day\")\n",
    "plt.ylabel(\"Energy Consumption (Wh)\")\n",
    "plt.title(\"Appliance Energy Consumption by Hour of the Day\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ff3f2",
   "metadata": {},
   "source": [
    "The hourly average did not provide to strong of an insight. As expected, energy consumption is lowest during sleeping hours. <br>\n",
    "Early evening has the peak on average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df[['Appliances', 'lights', 'T1', 'T2', 'T_out', 'RH_out', 'Windspeed', 'Tdewpoint', 'hour']])\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b804243",
   "metadata": {},
   "source": [
    "# Feedfoward Neural Network (FNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e42094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our features and target\n",
    "features = ['lights', 'T1', 'T2', 'T_out', 'RH_out', 'Windspeed', 'Tdewpoint', 'hour']\n",
    "target = 'Appliances'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea87554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare our data for training\n",
    "X = df[features]  # independent variables\n",
    "y = df[target]  # target variable\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef726004",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Set: {X_train.shape}, Testing Set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd79dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build of FNN \n",
    "model = Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),  # input\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # output layer for energy consumption prediction\n",
    "])\n",
    "\n",
    "# compile the model \n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# train the model \n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# model evaluation\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Neural Network MAE: {mae:.2f} Wh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa44659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss and validation loss from the training history\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.title(\"Training & Validation Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f911f1",
   "metadata": {},
   "source": [
    "# FNN Optimized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96272fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks to prevent overfitting and optimize learning\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5, min_lr=1e-5)\n",
    "\n",
    "# updated our FNN model\n",
    "model = Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),  # input Layer\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),  # dropout to reduce overfitting\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # output layer for regression\n",
    "])\n",
    "\n",
    "# compile the model with a lower learning rate for stable training\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "\n",
    "# train the model with early stopping to prevent overfitting\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=100, batch_size=16, \n",
    "    validation_data=(X_test, y_test), \n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Optimized Neural Network MAE: {mae:.2f} Wh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba754a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract loss and validation loss from the training history\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.title(\"Training & Validation Loss Over Epochs\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2779d0ec",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15510ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "train_size = int(0.8 * len(df))\n",
    "train_df = df.iloc[:train_size].reset_index(drop=True)  \n",
    "val_df = df.iloc[train_size:].reset_index(drop=True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence parameters\n",
    "seq_length = 60  \n",
    "ph = 5  \n",
    "\n",
    "# Prepare training sequences\n",
    "seq_arrays = []\n",
    "seq_labs = []\n",
    "\n",
    "for i in range(len(train_df) - seq_length - ph):\n",
    "    seq = train_df[X.columns].iloc[i:i + seq_length].values  \n",
    "    label = train_df[y.name].iloc[i + seq_length + ph - 1]\n",
    "    seq_arrays.append(seq)\n",
    "    seq_labs.append(label)\n",
    "\n",
    "seq_arrays = np.array(seq_arrays, dtype=np.float32)\n",
    "seq_labs = np.array(seq_labs, dtype=np.float32).reshape(-1)\n",
    "\n",
    "print(f\"LSTM Input Shape: {seq_arrays.shape}\") \n",
    "print(f\"LSTM Target Shape: {seq_labs.shape}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'LSTM_model1.keras'\n",
    "nb_features = X_train.shape[1]  \n",
    "nb_out = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, input_shape=(seq_length, nb_features), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=25, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=nb_out))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.005) \n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mse'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "model_checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    seq_arrays, seq_labs,\n",
    "    epochs=100,\n",
    "    batch_size=500,\n",
    "    validation_split=0.1,\n",
    "    verbose=2,\n",
    "    callbacks=[lr_scheduler, early_stopping, model_checkpoint]\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
